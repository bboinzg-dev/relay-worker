diff --git a/server.js b/server.js
index e3f62990eedd0c1bf661eb2f2b977e44ab988146..b9cd0c04222fe35e4ec47af74556b744e3f38592 100644
--- a/server.js
+++ b/server.js
@@ -150,56 +150,60 @@ authRouter.post('/logout', (_req, res) => res.json({ ok: true }));
 
 // ✅ /auth/* 경로로 확정 마운트 (항상 가장 먼저 잡히게)
 app.use('/auth', authRouter);
 
 // (구버전 호환) /login 으로 들어오면 같은 핸들러 사용
 app.post('/login', loginHandler);
 
 /* ---------------- Mount modular routers (after global middleware) ---------------- */
 try { app.use(require('./server.ai')); console.log('[BOOT] mounted /api/ai/resolve'); } catch (e) { console.error('[BOOT] ai/resolve mount error', e?.message||e); }
 try { app.use(require('./server.health'));   console.log('[BOOT] mounted /api/health'); } catch {}
 try { app.use(require('./server.optimize')); console.log('[BOOT] mounted /api/optimize/*'); } catch {}
 try { app.use(require('./server.checkout')); console.log('[BOOT] mounted /api/checkout/*'); } catch {}
 try { app.use(require('./server.bom'));      console.log('[BOOT] mounted /api/bom/*'); } catch {}
 try { app.use(require('./server.notify'));   console.log('[BOOT] mounted /api/notify/*'); } catch {}
 try { app.use(require('./server.market'));   console.log('[BOOT] mounted /api/listings, /api/purchase-requests, /api/bids'); } catch {}
 try { app.use(require('./src/routes/vision.upload')); console.log('[BOOT] mounted /api/vision/guess (upload)'); } catch {}
 try {
   const aiRouter = express.Router();
   const { VertexAI } = require('@google-cloud/vertexai');
 
   aiRouter.get('/api/ai/resolve', async (req, res) => {
     try {
       const q = String(req.query.q || '').trim();
       if (!q) return res.status(400).json({ ok: false, error: 'q required' });
 
+      const projectId = process.env.GOOGLE_CLOUD_PROJECT || process.env.GCP_PROJECT_ID;
+      const location = process.env.VERTEX_LOCATION || 'asia-northeast3';
+      const modelId = process.env.GEMINI_MODEL_EXTRACT || 'gemini-2.5-flash';
+
       const v = new VertexAI({
-        project: process.env.GOOGLE_CLOUD_PROJECT || process.env.GCP_PROJECT_ID,
-        location: process.env.VERTEX_LOCATION || 'asia-northeast3',
+        project: projectId,
+        location,
       });
       const mdl = v.getGenerativeModel({
-        model: process.env.GEMINI_MODEL_EXTRACT || 'gemini-2.5-flash',
+        model: modelId,
         systemInstruction: {
           parts: [{ text: 'Parse an electronics part query. Return STRICT JSON: {"brand": string|null, "codes": string[]}.' }],
         },
       });
       const out = await mdl.generateContent({
         contents: [{ role: 'user', parts: [{ text: `query: ${q}` }] }],
         generationConfig: {
           temperature: 0.2,
           responseMimeType: 'application/json',
           maxOutputTokens: 512,
         },
       });
 
       let parsed = {};
       try {
         parsed = JSON.parse(out?.response?.candidates?.[0]?.content?.parts?.[0]?.text || '{}');
       } catch {}
 
       const brand = typeof parsed?.brand === 'string' ? parsed.brand.trim() : '';
       const codes = Array.isArray(parsed?.codes)
         ? parsed.codes.map(x => String(x || '').trim()).filter(Boolean)
         : [];
 
       if (!brand || !codes.length) {
         return res.status(404).json({ ok: false, error: 'cannot resolve' });
