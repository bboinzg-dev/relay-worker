diff --git a/src/pipeline/ingestAuto.js b/src/pipeline/ingestAuto.js
index ca5f92b8de8d8b3a579378a2a2ea7d12732cff61..9c0d9ed7b802de9effb59c8dcb65f1e68b330ec9 100644
--- a/src/pipeline/ingestAuto.js
+++ b/src/pipeline/ingestAuto.js
@@ -1,81 +1,106 @@
 'use strict';
 
 const path = require('node:path');
 const fs = require('node:fs/promises');
 const os = require('node:os');
 const { execFile } = require('node:child_process');
 const { promisify } = require('node:util');
 const execFileP = promisify(execFile);
 
 const db = require('../../db');
 const { storage, parseGcsUri, readText, canonicalCoverPath } = require('../utils/gcs');
 const { extractText } = require('../utils/extract');
 const { getBlueprint } = require('../utils/blueprint');
 const { resolveBrand } = require('../utils/brand');
 const { detectVariantKeys } = require('../utils/ordering');
 const { extractPartsAndSpecsFromPdf } = require('../ai/datasheetExtract');
 const { extractFields } = require('./extractByBlueprint');
+const { aiCanonicalizeKeys } = require('./ai/canonKeys');
 const { saveExtractedSpecs } = require('./persist');
 const { explodeToRows } = require('../ingest/mpn-exploder');
 const { splitAndCarryPrefix } = require('../utils/mpn-exploder');
 const { ensureSpecColumnsForBlueprint } = require('./ensure-spec-columns');
 const { inferVariantKeys, normalizeSlug } = require('./variant-keys');
 const { classifyByGcs, extractValuesByGcs } = require('../services/vertex');
 const { processDocument: processDocAi } = require('../services/docai');
 
 const HARD_CAP_MS = Number(process.env.EXTRACT_HARD_CAP_MS || 120000);
 
 function withDeadline(promise, ms = HARD_CAP_MS, label = 'op') {
   const timeout = Number.isFinite(ms) && ms > 0 ? ms : HARD_CAP_MS;
   return new Promise((resolve, reject) => {
     const timer = setTimeout(() => {
       clearTimeout(timer);
       reject(new Error(`${label}_TIMEOUT`));
     }, timeout);
     Promise.resolve(promise)
       .then((value) => {
         clearTimeout(timer);
         resolve(value);
       })
       .catch((err) => {
         clearTimeout(timer);
         reject(err);
       });
   });
 }
 
 const FAST = String(process.env.INGEST_MODE || '').toUpperCase() === 'FAST' || process.env.FAST_INGEST === '1';
 const FAST_PAGES = [0, 1, -1]; // 첫 페이지, 2페이지, 마지막 페이지만
 
 const META_KEYS = new Set(['variant_keys','pn_template','ingest_options']);
 const BASE_KEYS = new Set([
   'family_slug','brand','code','pn','brand_norm','code_norm','pn_norm','series_code',
   'datasheet_uri','image_uri','datasheet_url','display_name','displayname',
   'cover','verified_in_doc','updated_at'
 ]);
 
+const RESERVED_SPEC_COLS = new Set([
+  'id','created_at','updated_at','brand','brand_norm','pn','pn_norm','code','series',
+  'image_uri','datasheet_uri','code_norm','series_code','display_name',
+  'displayname','datasheet_url','cover','verified_in_doc'
+]);
+
+const AUTO_CANON_MIN_CONF = Number(process.env.AUTO_CANON_MIN_CONF || '0.66');
+
+function normalizeDynamicSpecKey(raw) {
+  if (raw == null) return null;
+  let s = String(raw).trim();
+  if (!s) return null;
+  s = s.toLowerCase();
+  s = s.replace(/[–—―]/g, '-');
+  s = s.replace(/\s+/g, '_');
+  s = s.replace(/[^0-9a-z_]+/g, '_');
+  s = s.replace(/_+/g, '_');
+  s = s.replace(/^_+|_+$/g, '');
+  if (!s) return null;
+  if (s.length > 63) s = s.slice(0, 63);
+  if (RESERVED_SPEC_COLS.has(s)) return null;
+  return s;
+}
+
 const PN_CANDIDATE_RE = /[0-9A-Z][0-9A-Z\-_/().]{3,63}[0-9A-Z)]/gi;
 const PN_BLACKLIST_RE = /(pdf|font|xref|object|type0|ffff)/i;
 
 function escapeRegex(str) {
   return String(str || '').replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
 }
 
 function textContainsExact(text, pn) {
   if (!text || !pn) return false;
   const pattern = escapeRegex(String(pn).trim());
   if (!pattern) return false;
   const re = new RegExp(`(^|[^A-Za-z0-9])${pattern}(?=$|[^A-Za-z0-9])`, 'i');
   return re.test(String(text));
 }
 
 function normLower(s){ return String(s||'').trim().toLowerCase(); }
 
 function pickBrandHint(...values) {
   for (const value of values) {
     if (value == null) continue;
     const trimmed = String(value).trim();
     if (!trimmed) continue;
     if (trimmed.toLowerCase() === 'unknown') continue;
     return trimmed;
   }
diff --git a/src/pipeline/ingestAuto.js b/src/pipeline/ingestAuto.js
index ca5f92b8de8d8b3a579378a2a2ea7d12732cff61..9c0d9ed7b802de9effb59c8dcb65f1e68b330ec9 100644
--- a/src/pipeline/ingestAuto.js
+++ b/src/pipeline/ingestAuto.js
@@ -1055,70 +1080,195 @@ async function runAutoIngest(input = {}) {
           console.warn('[variant] ensure_blueprint_variant_columns failed:', err?.message || err);
         }
       }
     }
 
     if (Array.isArray(freshKeys) && freshKeys.length) {
       console.log('[variant] detected new keys', { family, brand: brandName, series: baseSeries, keys: freshKeys });
     }
   } catch (err) {
     console.warn('[variant] inferVariantKeys failed:', err?.message || err);
   }
 
   if (!disableEnsure) {
     await ensureSpecsTableByFamily(family);
     if (!variantColumnsEnsured) {
       try {
         await ensureBlueprintVariantColumns(family);
         variantColumnsEnsured = true;
       } catch (err) {
         console.warn('[variant] ensure_blueprint_variant_columns fallback failed:', err?.message || err);
       }
     }
   }
 
   await ensureSpecColumnsForBlueprint(qualified, blueprint);
-  colTypes = await getColumnTypes(qualified);
 
   const mpnsFromDoc = harvestMpnCandidates(
     extracted?.text ?? '',
     (baseSeries || series || code || '')
   );
   const mpnNormFromDoc = new Set(mpnsFromDoc.map((m) => normalizeCode(m)).filter(Boolean));
 
   const candidateMap = [];
   const candidateNormSet = new Set();
   for (const cand of candidates) {
     const trimmed = typeof cand === 'string' ? cand.trim() : String(cand || '');
     if (!trimmed) continue;
     const norm = normalizeCode(trimmed);
     if (!norm || candidateNormSet.has(norm)) continue;
     candidateNormSet.add(norm);
     candidateMap.push({ raw: trimmed, norm });
   }
 
-  const rawRows = Array.isArray(extracted.rows) && extracted.rows.length ? extracted.rows : [];
+  let rawRows = Array.isArray(extracted.rows) && extracted.rows.length ? extracted.rows : [];
+
+  if (process.env.AUTO_CANON_KEYS === '1' && rawRows.length) {
+    try {
+      const runtimeKeySet = new Set();
+      for (const row of rawRows) {
+        if (!row || typeof row !== 'object') continue;
+        for (const rawKey of Object.keys(row)) {
+          const trimmed = String(rawKey || '').trim();
+          if (!trimmed) continue;
+          const lower = trimmed.toLowerCase();
+          if (META_KEYS.has(lower) || BASE_KEYS.has(lower)) continue;
+          runtimeKeySet.add(trimmed);
+        }
+      }
+
+      const runtimeKeys = Array.from(runtimeKeySet);
+      if (runtimeKeys.length) {
+        const specColsRes = await db.query(
+          `
+          SELECT column_name
+            FROM information_schema.columns
+           WHERE table_schema='public' AND table_name = (
+             SELECT COALESCE(specs_table, $1||'_specs')
+               FROM public.component_registry
+              WHERE family_slug=$1
+           )
+          `,
+          [family]
+        );
+        const specCols = specColsRes.rows.map((r) => String(r.column_name || '').toLowerCase()).filter(Boolean);
+
+        const fieldKeysRes = await db.query(
+          `SELECT jsonb_object_keys(fields_json) AS k
+             FROM public.component_spec_blueprint
+            WHERE family_slug=$1`,
+          [family]
+        );
+        const fieldKeys = fieldKeysRes.rows.map((r) => String(r.k || '').toLowerCase()).filter(Boolean);
+
+        const variantKeysRes = await db.query(
+          `
+          WITH arr AS (
+            SELECT COALESCE(recipe->'variant_keys','[]'::jsonb) a
+              FROM public.extraction_recipe
+             WHERE family_slug=$1
+          )
+          SELECT (x->>'name') AS k FROM arr, LATERAL jsonb_array_elements(a) x
+          `,
+          [family]
+        );
+        const variantKeysFromDb = variantKeysRes.rows
+          .map((r) => String(r.k || '').toLowerCase())
+          .filter(Boolean);
+
+        const knownKeys = Array.from(new Set([...specCols, ...fieldKeys, ...variantKeysFromDb]));
+        const { map, newKeys } = await aiCanonicalizeKeys(family, runtimeKeys, knownKeys);
+
+        if (process.env.AUTO_ADD_FIELDS === '1' && Array.isArray(newKeys) && newKeys.length) {
+          const limitRaw = Number(process.env.AUTO_ADD_FIELDS_LIMIT || '20');
+          const limit = Number.isFinite(limitRaw) && limitRaw > 0 ? limitRaw : newKeys.length;
+          const target = newKeys.slice(0, limit);
+          if (target.length) {
+            try {
+              const ensureRes = await db.query(
+                'SELECT public.ensure_dynamic_spec_columns($1,$2::jsonb) AS created',
+                [family, JSON.stringify(target.map((k) => map?.[k]?.canonical || k))]
+              );
+              console.log('[schema] added columns', ensureRes?.rows?.[0]?.created);
+            } catch (err) {
+              console.warn('[schema] ensure_dynamic_spec_columns failed:', err?.message || err);
+            }
+          }
+        }
+
+        const aliasPairs = new Map();
+        const normalizedRows = [];
+        for (const row of rawRows) {
+          if (!row || typeof row !== 'object') {
+            normalizedRows.push(row);
+            continue;
+          }
+          const next = { ...row };
+          for (const rawKey of Object.keys(row)) {
+            const trimmed = String(rawKey || '').trim();
+            if (!trimmed) continue;
+            const lower = trimmed.toLowerCase();
+            if (META_KEYS.has(lower) || BASE_KEYS.has(lower)) continue;
+            const mapping = map?.[trimmed];
+            if (!mapping) continue;
+            const normalized = normalizeDynamicSpecKey(mapping.canonical || trimmed);
+            if (!normalized) continue;
+            if (
+              !Object.prototype.hasOwnProperty.call(next, normalized) ||
+              next[normalized] == null ||
+              next[normalized] === ''
+            ) {
+              next[normalized] = row[rawKey];
+            }
+            if (normalized !== rawKey) {
+              delete next[rawKey];
+            }
+            if (mapping.action === 'map' && mapping.conf >= AUTO_CANON_MIN_CONF) {
+              aliasPairs.set(trimmed, normalized);
+            }
+          }
+          normalizedRows.push(next);
+        }
+        rawRows = normalizedRows;
+
+        if (aliasPairs.size) {
+          for (const [aliasKey, canonicalKey] of aliasPairs.entries()) {
+            try {
+              await db.query('SELECT public.upsert_spec_alias($1,$2,$3)', [family, aliasKey, canonicalKey]);
+            } catch (err) {
+              console.warn('[schema] upsert_spec_alias failed:', err?.message || err);
+            }
+          }
+        }
+      }
+    } catch (err) {
+      console.warn('[schema] aiCanonicalizeKeys failed:', err?.message || err);
+    }
+  }
+
+  colTypes = await getColumnTypes(qualified);
+
   const baseRows = (rawRows.length ? rawRows : [{}]).map((row) => {
     const obj = row && typeof row === 'object' ? { ...row } : {};
     if (obj.brand == null) obj.brand = brandName;
     const fallbackSeries = obj.series_code || obj.series || baseSeries || null;
     if (fallbackSeries != null) {
       if (obj.series == null) obj.series = fallbackSeries;
       if (obj.series_code == null) obj.series_code = fallbackSeries;
     }
     if (obj.datasheet_uri == null) obj.datasheet_uri = gcsUri;
     if (coverUri && obj.cover == null) obj.cover = coverUri;
     return obj;
   });
 
   const explodedRows = explodeToRows(blueprint, baseRows);
   const physicalCols = new Set(colTypes ? [...colTypes.keys()] : []);
   const allowedSet = new Set((allowedKeys || []).map((k) => String(k || '').trim().toLowerCase()).filter(Boolean));
   const variantSet = new Set(variantKeys);
 
   const seenCodes = new Set();
   for (const row of explodedRows) {
     const seeds = [];
     const seenSeed = new Set();
     const pushSeed = (val) => {
       if (val == null) return;
       if (Array.isArray(val)) { val.forEach(pushSeed); return; }
